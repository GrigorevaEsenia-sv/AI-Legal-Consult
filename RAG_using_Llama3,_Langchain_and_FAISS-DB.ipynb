{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HuxGBa2QLS6G"
   },
   "source": [
    "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n",
    "<div class=\"align-center\">\n",
    "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
    "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
    "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Join Discord if you need help + ⭐ <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ⭐\n",
    "</div>\n",
    "\n",
    "To install Unsloth on your own computer, follow the installation instructions on our Github page [here](https://docs.unsloth.ai/get-started/installing-+-updating).\n",
    "\n",
    "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "Ti1ROS0JTln3"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "<center><img src=\"https://cdn.mos.cms.futurecdn.net/RNrVwVfRiyoKkrr8djHvf9-650-80.jpg.webp\"></center>\n",
    "<center><font color=\"BBBBBB\" size=2>(Image credit: Adobe Firefly - AI generated for Future, from Tom's guide)</font></center>\n",
    "\n",
    "## Objective\n",
    "\n",
    "Use Llama3 Langchain and ChromaDB to create a Retrieval Augmented Generation (RAG) system. This will allow us to ask questions about our documents (that were not included in the training data), without fine-tunning the Large Language Model (LLM).\n",
    "When using RAG, if you are given a question, you first do a retrieval step to fetch any relevant documents from a special database, a vector database where these documents were indexed.\n",
    "The data that we will use is the text of EU AI Act, approved on March 13, 2024.\n",
    "\n",
    "## Definitions\n",
    "\n",
    "* LLM - Large Language Model  \n",
    "* Llama3- LLM from Meta\n",
    "* Langchain - a framework designed to simplify the creation of applications using LLMs\n",
    "* Vector database - a database that organizes data through high-dimmensional vectors  \n",
    "* ChromaDB - vector database  \n",
    "* RAG - Retrieval Augmented Generation (see below more details about RAGs)\n",
    "\n",
    "## Model details\n",
    "\n",
    "* **Model**: Llama 3  \n",
    "* **Variation**: 8b-chat-hf  (8b: 8B dimm.; hf: HuggingFace)\n",
    "* **Version**: V1  \n",
    "* **Framework**: Transformers  \n",
    "\n",
    "Llama3 model is pretrained and fine-tuned with 15T+ (more than 15 Trillion) tokens and 8 to 70 Billion parameters which makes it one of the powerful open source models. It is a highly improvement over Llama2 model.\n",
    "\n",
    "\n",
    "## What is a Retrieval Augmented Generation (RAG) system?\n",
    "\n",
    "Large Language Models (LLMs) has proven their ability to understand context and provide accurate answers to various NLP tasks, including summarization, Q&A, when prompted. While being able to provide very good answers to questions about information that they were trained with, they tend to hallucinate when the topic is about information that they do \"not know\", i.e. was not included in their training data. Retrieval Augmented Generation combines external resources with LLMs. The main two components of a RAG are therefore a retriever and a generator.  \n",
    "\n",
    "The retriever part can be described as a system that is able to encode our data so that can be easily retrieved the relevant parts of it upon queriying it. The encoding is done using text embeddings, i.e. a model trained to create a vector representation of the information. The best option for implementing a retriever is a vector database. As vector database, there are multiple options, both open source or commercial products. Few examples are ChromaDB, Mevius, FAISS, Pinecone, Weaviate. Our option in this Notebook will be a local instance of ChromaDB (persistent).\n",
    "\n",
    "For the generator part, the obvious option is a LLM. In this Notebook we will use a quantized Llama3 model, from the Kaggle Models collection.  \n",
    "\n",
    "The orchestration of the retriever and generator will be done using Langchain. A specialized function from Langchain allows us to create the receiver-generator in one line of code.\n",
    "\n",
    "## The data\n",
    "\n",
    "The data that will be indexed in the vector database to make it searchable by the RAG system is the complete text of the European Union Artificial Intelligence Act. This is a European Union regulation on Artificial Intelligence (AI) in the European Union. Proposed by the European Commission on 21 April 2021, it was adopted on 13 March 2024.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xRPIQO2sTln5"
   },
   "source": [
    "# Installations, imports, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "R1IlSJZULS6k",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "40a2f291-6a26-4a3e-e36c-b14747379e9e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unsloth\n",
      "  Downloading unsloth-2025.6.2-py3-none-any.whl.metadata (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting unsloth_zoo>=2025.6.1 (from unsloth)\n",
      "  Downloading unsloth_zoo-2025.6.1-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting torch<=2.7.0,>=2.4.0 (from unsloth)\n",
      "  Downloading torch-2.7.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
      "  Downloading xformers-0.0.30-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting bitsandbytes (from unsloth)\n",
      "  Downloading bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Collecting triton>=3.0.0 (from unsloth)\n",
      "  Downloading triton-3.3.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth) (23.2)\n",
      "Collecting tyro (from unsloth)\n",
      "  Downloading tyro-0.9.24-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,>=4.51.3 (from unsloth)\n",
      "  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting datasets>=3.4.1 (from unsloth)\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting sentencepiece>=0.2.0 (from unsloth)\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting tqdm (from unsloth)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth) (5.9.6)\n",
      "Collecting wheel>=0.42.0 (from unsloth)\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.24.1)\n",
      "Collecting accelerate>=0.34.1 (from unsloth)\n",
      "  Downloading accelerate-1.7.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth)\n",
      "  Downloading trl-0.18.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting peft!=0.11.0,>=0.7.1 (from unsloth)\n",
      "  Downloading peft-0.15.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting protobuf (from unsloth)\n",
      "  Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting huggingface_hub (from unsloth)\n",
      "  Downloading huggingface_hub-0.33.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting hf_transfer (from unsloth)\n",
      "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting diffusers (from unsloth)\n",
      "  Downloading diffusers-0.33.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.16.0+cu118)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.1)\n",
      "Collecting safetensors>=0.4.3 (from accelerate>=0.34.1->unsloth)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=3.4.1->unsloth) (3.9.0)\n",
      "Collecting pyarrow>=15.0.0 (from datasets>=3.4.1->unsloth)\n",
      "  Downloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets>=3.4.1->unsloth)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets>=3.4.1->unsloth)\n",
      "  Downloading pandas-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests>=2.32.2 (from datasets>=3.4.1->unsloth)\n",
      "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting xxhash (from datasets>=3.4.1->unsloth)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets>=3.4.1->unsloth)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (2023.4.0)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->unsloth) (4.4.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface_hub->unsloth)\n",
      "  Downloading hf_xet-1.1.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface_hub->unsloth)\n",
      "  Downloading typing_extensions-4.14.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting sympy>=1.13.3 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<=2.7.0,>=2.4.0->unsloth) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<=2.7.0,>=2.4.0->unsloth) (3.1.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
      "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
      "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
      "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton>=3.0.0 (from unsloth)\n",
      "  Downloading triton-3.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.10/dist-packages (from triton>=3.0.0->unsloth) (68.2.2)\n",
      "Collecting regex!=2019.12.17 (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,>=4.51.3->unsloth)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers<0.22,>=0.21 (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,>=4.51.3->unsloth)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting protobuf (from unsloth)\n",
      "  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n",
      "Collecting cut_cross_entropy (from unsloth_zoo>=2025.6.1->unsloth)\n",
      "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2025.6.1->unsloth) (9.3.0)\n",
      "Collecting msgspec (from unsloth_zoo>=2025.6.1->unsloth)\n",
      "  Downloading msgspec-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: importlib-metadata in /usr/lib/python3/dist-packages (from diffusers->unsloth) (4.6.4)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision (from unsloth)\n",
      "  Downloading torchvision-0.22.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "  Downloading torchvision-0.22.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting docstring-parser>=0.15 (from tyro->unsloth)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting rich>=11.1.0 (from tyro->unsloth)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting shtab>=1.5.6 (from tyro->unsloth)\n",
      "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting typeguard>=4.0.0 (from tyro->unsloth)\n",
      "  Downloading typeguard-4.4.3-py3-none-any.whl.metadata (3.4 kB)\n",
      "INFO: pip is looking at multiple versions of fsspec[http] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth)\n",
      "  Downloading aiohttp-3.12.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=3.4.1->unsloth) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=3.4.1->unsloth) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=3.4.1->unsloth) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=3.4.1->unsloth) (2022.12.7)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=11.1.0->tyro->unsloth)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth) (2.16.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.13.3->torch<=2.7.0,>=2.4.0->unsloth) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<=2.7.0,>=2.4.0->unsloth) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=3.4.1->unsloth) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets>=3.4.1->unsloth)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets>=3.4.1->unsloth)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth)\n",
      "  Downloading frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth)\n",
      "  Downloading multidict-6.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth)\n",
      "  Downloading propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth)\n",
      "  Downloading yarl-1.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.9/73.9 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.4.1->unsloth) (1.16.0)\n",
      "Downloading unsloth-2025.6.2-py3-none-any.whl (276 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.0/277.0 kB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.7.0-py3-none-any.whl (362 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.1/362.1 kB\u001b[0m \u001b[31m106.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m188.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.33.0-py3-none-any.whl (514 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m514.8/514.8 kB\u001b[0m \u001b[31m182.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.15.2-py3-none-any.whl (411 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.1/411.1 kB\u001b[0m \u001b[31m166.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m222.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.7.0-cp310-cp310-manylinux_2_28_x86_64.whl (865.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.4/156.4 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m237.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m181.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m189.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m220.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m157.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m221.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m220.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading trl-0.18.1-py3-none-any.whl (366 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m366.3/366.3 kB\u001b[0m \u001b[31m120.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading unsloth_zoo-2025.6.1-py3-none-any.whl (147 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.4/147.4 kB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m183.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xformers-0.0.30-cp310-cp310-manylinux_2_28_x86_64.whl (31.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.5/31.5 MB\u001b[0m \u001b[31m162.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl (67.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m128.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading diffusers-0.33.1-py3-none-any.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m257.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m266.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.22.0-cp310-cp310-manylinux_2_28_x86_64.whl (7.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m199.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tyro-0.9.24-py3-none-any.whl (128 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.3/128.3 kB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m260.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m135.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m159.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.8/64.8 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.2/243.2 kB\u001b[0m \u001b[31m110.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m162.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m213.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m248.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typeguard-4.4.3-py3-none-any.whl (34 kB)\n",
      "Downloading typing_extensions-4.14.0-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
      "Downloading msgspec-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.6/211.6 kB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m242.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.12.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m240.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m159.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m136.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (222 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.9/222.9 kB\u001b[0m \u001b[31m109.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading multidict-6.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (219 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.1/219.1 kB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (198 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.3/198.3 kB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.1/326.1 kB\u001b[0m \u001b[31m132.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece, pytz, nvidia-cusparselt-cu12, xxhash, wheel, tzdata, typing-extensions, triton, tqdm, sympy, shtab, safetensors, requests, regex, pyarrow, protobuf, propcache, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgspec, mdurl, hf-xet, hf_transfer, fsspec, frozenlist, docstring-parser, dill, async-timeout, aiohappyeyeballs, typeguard, pandas, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, multiprocess, multidict, markdown-it-py, huggingface_hub, aiosignal, yarl, tokenizers, rich, nvidia-cusolver-cu12, diffusers, tyro, transformers, torch, aiohttp, xformers, torchvision, cut_cross_entropy, bitsandbytes, accelerate, peft, datasets, trl, unsloth_zoo, unsloth\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.41.3\n",
      "    Uninstalling wheel-0.41.3:\n",
      "      Successfully uninstalled wheel-0.41.3\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.1.0\n",
      "    Uninstalling triton-2.1.0:\n",
      "      Successfully uninstalled triton-2.1.0\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.12\n",
      "    Uninstalling sympy-1.12:\n",
      "      Successfully uninstalled sympy-1.12\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.0+cu118\n",
      "    Uninstalling torch-2.1.0+cu118:\n",
      "      Successfully uninstalled torch-2.1.0+cu118\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.16.0+cu118\n",
      "    Uninstalling torchvision-0.16.0+cu118:\n",
      "      Successfully uninstalled torchvision-0.16.0+cu118\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-1.7.0 aiohappyeyeballs-2.6.1 aiohttp-3.12.12 aiosignal-1.3.2 async-timeout-5.0.1 bitsandbytes-0.46.0 cut_cross_entropy-25.1.1 datasets-3.6.0 diffusers-0.33.1 dill-0.3.8 docstring-parser-0.16 frozenlist-1.7.0 fsspec-2025.3.0 hf-xet-1.1.3 hf_transfer-0.1.9 huggingface_hub-0.33.0 markdown-it-py-3.0.0 mdurl-0.1.2 msgspec-0.19.0 multidict-6.4.4 multiprocess-0.70.16 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 pandas-2.3.0 peft-0.15.2 propcache-0.3.2 protobuf-3.20.3 pyarrow-20.0.0 pytz-2025.2 regex-2024.11.6 requests-2.32.4 rich-14.0.0 safetensors-0.5.3 sentencepiece-0.2.0 shtab-1.7.2 sympy-1.14.0 tokenizers-0.21.1 torch-2.7.0 torchvision-0.22.0 tqdm-4.67.1 transformers-4.52.4 triton-3.3.0 trl-0.18.1 typeguard-4.4.3 typing-extensions-4.14.0 tyro-0.9.24 tzdata-2025.2 unsloth-2025.6.2 unsloth_zoo-2025.6.1 wheel-0.45.1 xformers-0.0.30 xxhash-3.5.0 yarl-1.20.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.25-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.65 (from langchain_community)\n",
      "  Downloading langchain_core-0.3.65-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain<1.0.0,>=0.3.25 (from langchain_community)\n",
      "  Downloading langchain-0.3.25-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain_community)\n",
      "  Downloading sqlalchemy-2.0.41-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.12.12)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain_community)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting langsmith<0.4,>=0.1.125 (from langchain_community)\n",
      "  Downloading langsmith-0.3.45-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting numpy>=1.26.2 (from langchain_community)\n",
      "  Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain<1.0.0,>=0.3.25->langchain_community)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain<1.0.0,>=0.3.25->langchain_community)\n",
      "  Downloading pydantic-2.11.6-py3-none-any.whl.metadata (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<6.0,>=4.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.65->langchain_community)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain_community) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain_community) (4.14.0)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.4,>=0.1.125->langchain_community)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.125->langchain_community)\n",
      "  Downloading orjson-3.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.125->langchain_community)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.125->langchain_community)\n",
      "  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2022.12.7)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain_community)\n",
      "  Downloading greenlet-3.2.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.0.0)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.65->langchain_community) (2.4)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain_community)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain_community)\n",
      "  Downloading pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.1.3)\n",
      "Downloading langchain_community-0.3.25-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m155.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading langchain-0.3.25-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m156.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.65-py3-none-any.whl (438 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.1/438.1 kB\u001b[0m \u001b[31m148.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.3.45-py3-none-any.whl (363 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.0/363.0 kB\u001b[0m \u001b[31m129.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m222.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sqlalchemy-2.0.41-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m258.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading greenlet-3.2.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (582 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m582.2/582.2 kB\u001b[0m \u001b[31m172.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (132 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.11.6-py3-none-any.whl (444 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.7/444.7 kB\u001b[0m \u001b[31m154.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m249.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m237.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: zstandard, typing-inspection, tenacity, python-dotenv, pydantic-core, orjson, numpy, mypy-extensions, marshmallow, jsonpatch, httpx-sse, h11, greenlet, async-timeout, annotated-types, typing-inspect, SQLAlchemy, requests-toolbelt, pydantic, httpcore, pydantic-settings, httpx, dataclasses-json, langsmith, langchain-core, langchain-text-splitters, langchain, langchain_community\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.1\n",
      "    Uninstalling numpy-1.24.1:\n",
      "      Successfully uninstalled numpy-1.24.1\n",
      "  Attempting uninstall: async-timeout\n",
      "    Found existing installation: async-timeout 5.0.1\n",
      "    Uninstalling async-timeout-5.0.1:\n",
      "      Successfully uninstalled async-timeout-5.0.1\n",
      "Successfully installed SQLAlchemy-2.0.41 annotated-types-0.7.0 async-timeout-4.0.3 dataclasses-json-0.6.7 greenlet-3.2.3 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 httpx-sse-0.4.0 jsonpatch-1.33 langchain-0.3.25 langchain-core-0.3.65 langchain-text-splitters-0.3.8 langchain_community-0.3.25 langsmith-0.3.45 marshmallow-3.26.1 mypy-extensions-1.1.0 numpy-2.2.6 orjson-3.10.18 pydantic-2.11.6 pydantic-core-2.33.2 pydantic-settings-2.9.1 python-dotenv-1.1.0 requests-toolbelt-1.0.0 tenacity-9.1.2 typing-inspect-0.9.0 typing-inspection-0.4.1 zstandard-0.23.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_community "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_huggingface\n",
      "  Downloading langchain_huggingface-0.3.0-py3-none-any.whl.metadata (996 bytes)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.65 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (0.3.65)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (0.21.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.30.2 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (0.33.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.30.2->langchain_huggingface) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.30.2->langchain_huggingface) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.30.2->langchain_huggingface) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.30.2->langchain_huggingface) (6.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.30.2->langchain_huggingface) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.30.2->langchain_huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.30.2->langchain_huggingface) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.30.2->langchain_huggingface) (1.1.3)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.3.45 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (0.3.45)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (1.33)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (2.11.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (2.4)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.30.2->langchain_huggingface) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.30.2->langchain_huggingface) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.30.2->langchain_huggingface) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.30.2->langchain_huggingface) (2022.12.7)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (4.0.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (1.1.3)\n",
      "Downloading langchain_huggingface-0.3.0-py3-none-any.whl (27 kB)\n",
      "Installing collected packages: langchain_huggingface\n",
      "Successfully installed langchain_huggingface-0.3.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.26.4\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m309.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.6\n",
      "    Uninstalling numpy-2.2.6:\n",
      "      Successfully uninstalled numpy-2.2.6\n",
      "Successfully installed numpy-1.26.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.52.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.7.0)\n",
      "Collecting scikit-learn (from sentence_transformers)\n",
      "  Downloading scikit_learn-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n",
      "Collecting scipy (from sentence_transformers)\n",
      "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.33.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.14.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.4)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (1.1.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.10/dist-packages (from triton==3.3.0->torch>=1.11.0->sentence_transformers) (68.2.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.2.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.3)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence_transformers)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence_transformers)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2022.12.7)\n",
      "Downloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.7/345.7 kB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m230.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m174.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, sentence_transformers\n",
      "Successfully installed joblib-1.5.1 scikit-learn-1.7.0 scipy-1.15.3 sentence_transformers-4.1.0 threadpoolctl-3.6.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "QmUBVEnvCDJv",
    "outputId": "72d0c44b-9c90-4fb8-ecdb-d73142709741"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.6.2: Fast Llama patching. Transformers: 4.52.4.\n",
      "   \\\\   /|    NVIDIA A40. Num GPUs = 1. Max memory: 44.448 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
    "fourbit_models = [\n",
    "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 2x faster\n",
    "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
    "    \"unsloth/Mistral-Small-Instruct-2409\",     # Mistral 22b 2x faster!\n",
    "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
    "    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n",
    "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
    "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
    "\n",
    "    \"unsloth/Llama-3.2-1B-bnb-4bit\",           # NEW! Llama 3.2 models\n",
    "    \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\",\n",
    "    \"unsloth/Llama-3.2-3B-bnb-4bit\",\n",
    "    \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\",\n",
    "\n",
    "] # More models at https://huggingface.co/unsloth\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Llama-3.2-3B-Instruct\", # or choose \"unsloth/Llama-3.2-1B-Instruct\"\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3DKyR6PTln8"
   },
   "source": [
    "# Initialize model, tokenizer, query pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_q19tSITln8"
   },
   "source": [
    "Define the model, the device, and the `bitsandbytes` configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "from time import time\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"llama-3.1\",\n",
    ")\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    convos = examples[\"conversations\"]\n",
    "    texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in convos]\n",
    "    return { \"text\" : texts, }\n",
    "pass\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"mlabonne/FineTome-100k\", split = \"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cW1mESIxTln9"
   },
   "source": [
    "Prepare the model and the tokenizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdPjlV_sTln9"
   },
   "source": [
    "Netx, we define the query pipeline.  \n",
    "In order to work correctly when we will define the HuggingFace pipeline, we will need to define here the max_length (to avoid falling back on the very short default length of `20`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare pipeline: 0.004 sec.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from time import time\n",
    "import transformers\n",
    "\n",
    "time_start = time()\n",
    "query_pipeline = transformers.pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        torch_dtype=torch.float16,\n",
    "        max_length=2048,\n",
    "        device_map=\"auto\",)\n",
    "time_end = time()\n",
    "print(f\"Prepare pipeline: {round(time_end-time_start, 3)} sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MF-tOM9Tln-"
   },
   "source": [
    "We define a function for testing the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "_kg_hide-input": false,
    "id": "NruAwxg7Tln-"
   },
   "outputs": [],
   "source": [
    "def test_model(tokenizer, pipeline, message):\n",
    "    \"\"\"\n",
    "    Perform a query\n",
    "    print the result\n",
    "    Args:\n",
    "        tokenizer: the tokenizer\n",
    "        pipeline: the pipeline\n",
    "        message: the prompt\n",
    "    Returns\n",
    "        None\n",
    "    \"\"\"\n",
    "    time_start = time()\n",
    "    sequences = pipeline(\n",
    "        message,\n",
    "        do_sample=True,\n",
    "        top_k=10,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        max_length=200,)\n",
    "    time_end = time()\n",
    "    total_time = f\"{round(time_end-time_start, 3)} sec.\"\n",
    "\n",
    "    question = sequences[0]['generated_text'][:len(message)]\n",
    "    answer = sequences[0]['generated_text'][len(message):]\n",
    "\n",
    "    return f\"Question: {question}\\nAnswer: {answer}\\nTotal time: {total_time}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30WfMjJvTln-"
   },
   "source": [
    "## Test the query pipeline\n",
    "\n",
    "We test the pipeline with few queries about European Union Artificial Intelligence Act (EU AI Act)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Edy4TU33Tln-"
   },
   "source": [
    "We also define here an utility function. This function will be used to display the output from the answer of the LLM.  \n",
    "We include the calculation time, the question and the answer, formated so that will be easy to recognise them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "nCoN37OnTln_"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "def colorize_text(text):\n",
    "    for word, color in zip([\"Reasoning\", \"Question\", \"Answer\", \"Total time\"], [\"blue\", \"red\", \"green\", \"magenta\"]):\n",
    "        text = text.replace(f\"{word}:\", f\"\\n\\n**<font color='{color}'>{word}:</font>**\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LD73BOQsTln_"
   },
   "source": [
    "Let's test now the pipeline with few queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Please explain what is EU AI Act.\n",
       "\n",
       "\n",
       "**<font color='green'>Answer:</font>**  The European Union (EU) has proposed a new regulation on Artificial Intelligence (AI) called the EU Artificial Intelligence (AI) Act. The regulation aims to ensure that AI systems are designed and developed in a way that is fair, transparent, and accountable.\n",
       "The EU AI Act is a proposed regulation that aims to:\n",
       "1. **Define AI**: The regulation proposes a definition of AI that includes machine learning, deep learning, and other forms of AI.\n",
       "2. **Establish principles for AI development**: The regulation outlines principles for the development of AI systems, including principles related to transparency, explainability, and accountability.\n",
       "3. **Ensure human rights**: The regulation emphasizes the importance of respecting human rights, including the right to privacy, the right to non-discrimination, and the right to freedom of expression.\n",
       "4. **Protect vulnerable groups**: The regulation requires AI developers to take into account the potential impact of AI on vulnerable groups, such as children, older adults\n",
       "\n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 7.35 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = test_model(tokenizer,\n",
    "                    query_pipeline,\n",
    "                   \"Please explain what is EU AI Act.\")\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Проблема такая. Хотел договориться с сыном по-хорошему прописать жену в квартире, но получил отказ. Хотя сын сам не живет со мной уже почти 10 лет. Вопрос: могу ли я его выписать из квартиры (социальный найм) чтобы прописать жену?\n",
       "\n",
       "\n",
       "**<font color='green'>Answer:</font>**  \n",
       "\n",
       "Всего на счету 5 лет опыта работы в сфере социального найма, 2 года опыта работы в сфере аренды, 1 год опыта работы в сфере управления имуществом. Понимаете, что это все равно не достаточно для того, чтобы решить эту проблему?\n",
       "\n",
       "Вопрос: Как можно решить эту проблему? \n",
       "\n",
       "Вопрос: Как можно решить эту проблему? \n",
       "\n",
       "Вопрос: Как можно решить эту проблему? \n",
       "\n",
       "Вопрос: Как можно решить эту проблемю? \n",
       "\n",
       "Вопрос\n",
       "\n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 4.271 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = test_model(tokenizer,\n",
    "                    query_pipeline,\n",
    "                   \"Проблема такая. Хотел договориться с сыном по-хорошему прописать жену в квартире, но получил отказ. Хотя сын сам не живет со мной уже почти 10 лет. Вопрос: могу ли я его выписать из квартиры (социальный найм) чтобы прописать жену?\")\n",
    "display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJscZl1_TloA"
   },
   "source": [
    "The answer is not really useful. Let's try to build a RAG system specialized to answer questions about EU AI Act."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbIDFpbBTloA"
   },
   "source": [
    "# Retrieval Augmented Generation\n",
    "\n",
    "In order to build the RAG system, we will perform the following steps:\n",
    "* Test the model using a HuggingFacePipeline;  \n",
    "* Ingest the document using PyPdfLoader;\n",
    "* Chunk the documents (with chunk size 1000), making sure we have also a partial overlap (of 100 characters);  \n",
    "* Create embeddings and ingest the transformed text (text from pdf, chunked with overlap, embedded, and indexed) in the vector database;  \n",
    "* Create the RequestQA pipeline (that includes the retrieval step and the generation step)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-23T19:22:16.434937Z",
     "iopub.status.busy": "2023-09-23T19:22:16.433666Z",
     "iopub.status.idle": "2023-09-23T19:22:16.440864Z",
     "shell.execute_reply": "2023-09-23T19:22:16.439217Z",
     "shell.execute_reply.started": "2023-09-23T19:22:16.434891Z"
    },
    "id": "o3KuVwcqTloA"
   },
   "source": [
    "## Check the model with a HuggingFace pipeline\n",
    "\n",
    "\n",
    "We check the model with a HF pipeline, using a query about the meaning of EU AI Act. We will need to use the HuggingFacePipeline in order to integrate easier with the Langchain tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Please explain what EU AI Act is.\n",
       "\n",
       "\n",
       "**<font color='green'>Answer:</font>** Please explain what EU AI Act is. What are the purposes, objectives, and goals of the EU AI Act? The EU AI Act is a proposed regulation by the European Union aimed at ensuring the safe and responsible development and use of Artificial Intelligence (AI) in the EU.\n",
       "The EU AI Act is a comprehensive regulation that sets out a framework for the development and use of AI in the EU. The main objectives of the EU AI Act are:\n",
       "1. **Protecting fundamental rights**: The EU AI Act aims to protect the fundamental rights of EU citizens, including their right to privacy, right to data protection, and right to non-discrimination.\n",
       "2. **Ensuring accountability**: The EU AI Act requires companies and organizations to be accountable for the development and use of AI, including the potential risks and consequences associated with it.\n",
       "3. **Promoting transparency**: The EU AI Act promotes transparency in the development and use of AI, including the publication of AI-related data and the disclosure of AI-related risks.\n",
       "4. **Fostering innovation**: The EU AI Act aims to foster innovation in the development and use of AI, including the development of new AI technologies and applications.\n",
       "5. **Ensuring human oversight**: The EU AI Act requires human oversight of AI systems, including the use of human judgment and decision-making in high-stakes applications.\n",
       "\n",
       "The EU AI Act also sets out specific requirements for the development and use of AI, including:\n",
       "1. **Human oversight**: AI systems must be designed to allow for human oversight and intervention.\n",
       "2. **Transparency**: AI systems must be designed to be transparent about their decision-making processes and outcomes.\n",
       "3. **Explainability**: AI systems must be designed to be explainable, including the use of techniques such as model interpretability and model-agnostic explanations.\n",
       "4. **Accountability**: Companies and organizations must be held accountable for the development and use of AI, including the potential risks and consequences associated with it.\n",
       "5. **Data protection**: AI systems must be designed to protect personal data, including the use of data minimization, data anonymization, and data pseudonymization.\n",
       "\n",
       "Overall, the EU AI Act aims to ensure that the development and use of AI in the EU is safe, responsible, and transparent, and that it aligns with the fundamental rights and values of EU citizens.\n",
       "\n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 15.579 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm = HuggingFacePipeline(pipeline=query_pipeline)\n",
    "\n",
    "# checking again that everything is working fine\n",
    "time_start = time()\n",
    "question = \"Please explain what EU AI Act is.\"\n",
    "response = llm(prompt=question)\n",
    "time_end = time()\n",
    "total_time = f\"{round(time_end-time_start, 3)} sec.\"\n",
    "full_response =  f\"Question: {question}\\nAnswer: {response}\\nTotal time: {total_time}\"\n",
    "display(Markdown(colorize_text(full_response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9IyiWQo1TloB"
   },
   "source": [
    "## Загрузка данных из ГАРАНТ API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "bTiR5GBfVyGb"
   },
   "outputs": [],
   "source": [
    "DOC_PATH = 'data/raw/housing_code_garant/1.html'\n",
    "GARANT_API_KEY = \"003ac54e243711f095560050568d72f0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "NI7KL2NEWrFP",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# from typing import List, Dict, Optional\n",
    "# import json\n",
    "\n",
    "# class GarantAPILoader:\n",
    "#     def __init__(self, api_key: str):\n",
    "#         self.base_url = \"https://api.garant.ru/v1\"\n",
    "#         self.headers = {\n",
    "#             \"Accept\": \"application/json\",\n",
    "#             \"Content-Type\": \"application/json\",\n",
    "#             \"Authorization\": f\"Bearer {api_key}\"\n",
    "#         }\n",
    "\n",
    "#     def search_documents(self, text: str, count: int = 2,\n",
    "#                          kind: List[str] = [\"001\"],\n",
    "#                          sort: int = 0, sortOrder: int = 0) -> Optional[List[Dict]]:\n",
    "#         \"\"\"Поиск документов через API ГАРАНТ\"\"\"\n",
    "#         url = f\"{self.base_url}/search\"\n",
    "#         payload = {\n",
    "#             \"text\": text,\n",
    "#             \"count\": min(count, 30),  # API ограничивает максимум 30 документов\n",
    "#             \"kind\": kind,\n",
    "#             \"sort\": sort,  # 0 - по релевантности\n",
    "#             \"sortOrder\": sortOrder  # 0 - по убыванию\n",
    "#         }\n",
    "\n",
    "#         try:\n",
    "#             response = requests.post(url, headers=self.headers, json=payload)\n",
    "#             response.raise_for_status()\n",
    "#             return response.json().get(\"documents\", [])\n",
    "#         except requests.exceptions.RequestException as e:\n",
    "#             print(f\"Ошибка поиска документов: {str(e)}\")\n",
    "#             return None\n",
    "\n",
    "#     def export_html(self, topic_id: int) -> Optional[str]:\n",
    "#         \"\"\"Экспорт документа в HTML формате\"\"\"\n",
    "#         url = f\"{self.base_url}/topic/{topic_id}/html\"\n",
    "\n",
    "#         try:\n",
    "#             response = requests.get(url, headers=self.headers)\n",
    "#             response.raise_for_status()\n",
    "#             html_data = response.json()\n",
    "\n",
    "#             # Обработка HTML страниц\n",
    "#             full_html = []\n",
    "#             for page in html_data.get(\"items\", []):\n",
    "#                 soup = BeautifulSoup(page[\"text\"], 'html.parser')\n",
    "\n",
    "#                 # Удаление ненужных элементов\n",
    "#                 for elem in soup.find_all(class_=[\"comment\", \"ad\", \"hidden\"]):\n",
    "#                     elem.decompose()\n",
    "\n",
    "#                 full_html.append(str(soup))\n",
    "\n",
    "#             return \"\\n\".join(full_html)\n",
    "#         except requests.exceptions.RequestException as e:\n",
    "#             print(f\"Ошибка экспорта документа {topic_id}: {str(e)}\")\n",
    "#             return None\n",
    "\n",
    "#     def process_search_results(self, query) -> List[Dict]:\n",
    "#         \"\"\"Полный процесс: поиск + экспорт\"\"\"\n",
    "#         documents = self.search_documents(**query)\n",
    "#         if not documents:\n",
    "#             return []\n",
    "\n",
    "#         results = []\n",
    "#         for doc in documents:  # Берем первые 2 документа\n",
    "#             html_content = self.export_html(doc[\"topic\"])\n",
    "#             if html_content:\n",
    "#                 results.append({\n",
    "#                     \"title\": doc[\"name\"],\n",
    "#                     \"url\": f\"https://api.garant.ru/v1/topic/{doc['topic']}/html\",\n",
    "#                     \"topic_id\": doc[\"topic\"],\n",
    "#                     \"html\": html_content  # Для примера показываем часть контента\n",
    "#                 })\n",
    "\n",
    "#         return results\n",
    "\n",
    "# loader = GarantAPILoader(api_key=GARANT_API_KEY)\n",
    "\n",
    "# # Параметры поиска (можно менять)\n",
    "# search_params = {\n",
    "#     \"text\": \"перепланировка квартиры\",\n",
    "#     \"count\": 2,\n",
    "#     \"kind\": [\"001\"],  # Федеральное законодательство\n",
    "#     \"sort\": 0,  # По релевантности\n",
    "#     \"sortOrder\": 0  # По убыванию\n",
    "# }\n",
    "\n",
    "# results = loader.process_search_results(search_params)\n",
    "\n",
    "# print(f\"Найдено документов: {len(results)}\")\n",
    "# for idx, doc in enumerate(results, 1):\n",
    "#     with open(f'data/raw/housing_code/garant/{idx}.html', 'w') as f:\n",
    "#         f.write(doc['html'])\n",
    "#     print(f\"Ссылка: {doc['url']}\")\n",
    "#     print(f\"\\nДокумент #{idx}:\")\n",
    "#     print(f\"HTML: {doc['html'][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kO079LGMTloC"
   },
   "source": [
    "## Split data in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import re\n",
    "import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "_kg_hide-input": false,
    "id": "EAx5ihADTloB"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Очистка текста от HTML-сущностей и специальных пробелов с сохранением переносов строк.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return text\n",
    "\n",
    "    # Декодируем HTML-сущности\n",
    "    text = html.unescape(text)\n",
    "\n",
    "    # Заменяем специальные пробелы на обычные, сохраняя переносы строк\n",
    "    text = re.sub(r'[\\xa0\\u200b\\u202f]+', ' ', text)\n",
    "\n",
    "    return text.lstrip('.;, ')\n",
    "\n",
    "def load_and_chunk_html_documents(file_path, chunk_size=1600, chunk_overlap=150):\n",
    "    \"\"\"\n",
    "    Загружает HTML документ, извлекает текст, нарезает на чанки и создает векторное хранилище.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Путь к HTML файлу\n",
    "        chunk_size (int): Размер чанка в символах\n",
    "        chunk_overlap (int): Перекрытие между чанками\n",
    "\n",
    "    Returns:\n",
    "        FAISS: Векторное хранилище с чанками документа\n",
    "    \"\"\"\n",
    "    # Загрузка и парсинг HTML\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        html_content = file.read()\n",
    "\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Удаление ненужных тегов (стили, скрипты)\n",
    "    for tag in soup(['style', 'script', 'meta', 'link', 'noscript', 'iframe', 'svg']):\n",
    "        tag.decompose()\n",
    "\n",
    "    # Извлечение структурированного текста\n",
    "    sections = []\n",
    "    current_section = \"\"\n",
    "\n",
    "    # Обработка структуры документа (разделы, главы, статьи)\n",
    "    for element in soup.find_all(['h1', 'h2', 'h3', 'h4', 'p', 'div', 'article', 'section']):\n",
    "        element_text = clean_text(element.get_text())\n",
    "        if not element_text:\n",
    "            continue\n",
    "\n",
    "        if element.name in ['h1', 'h2', 'h3', 'h4']:\n",
    "            if current_section:\n",
    "                sections.append(current_section.strip())\n",
    "                current_section = \"\"\n",
    "            current_section += f\"\\n{element_text.upper()}\\n\"\n",
    "        else:\n",
    "            current_section += element_text + \" \"\n",
    "\n",
    "    if current_section:\n",
    "        sections.append(current_section.strip())\n",
    "\n",
    "    # Настройка сплиттера для юридических текстов\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=['\\n\\n', '\\n', ';', '. ']\n",
    "    )\n",
    "\n",
    "    # Нарезка на чанки\n",
    "    chunks = []\n",
    "    metadatas = []\n",
    "\n",
    "    metadata = dict()\n",
    "\n",
    "    print(f'len(sections) {len(sections)}')\n",
    "    for section in sections:\n",
    "        section_chunks = text_splitter.split_text(section)\n",
    "\n",
    "        # Извлечение метаданных (раздел, глава, статья) из текста\n",
    "        print(f'len(section_chunks) {len(section_chunks)}')\n",
    "        for chunk in section_chunks:\n",
    "            current_metadata = metadata.copy()\n",
    "            lines = chunk.split('\\n')\n",
    "            for line in lines:\n",
    "                line = clean_text(line)\n",
    "\n",
    "                if line.startswith('Раздел'):\n",
    "                    current_metadata['section'] = line.strip()\n",
    "                elif line.startswith('Глава'):\n",
    "                    current_metadata['chapter'] = line.strip()\n",
    "                elif line.startswith('Статья'):\n",
    "                    current_metadata['article'] = line.strip()\n",
    "\n",
    "            chunks.append(chunk)\n",
    "            metadatas.append(metadata)\n",
    "            metadata = current_metadata\n",
    "\n",
    "    return chunks, metadatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "b8a_DCvYXHs6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(sections) 2\n",
      "len(section_chunks) 1\n",
      "len(section_chunks) 3718\n"
     ]
    }
   ],
   "source": [
    "doc_path = 'data/raw/housing_code_garant/1.html'\n",
    "\n",
    "# Загрузка документа и создание векторного хранилища\n",
    "chunks, metadatas = load_and_chunk_html_documents(doc_path)\n",
    "\n",
    "# Инициализация эмбеддингов\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BwjWMYdOTloC"
   },
   "source": [
    "## Creating Embeddings and Storing in Vector Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ynqJSldTloC"
   },
   "source": [
    "Create the embeddings using Sentence Transformer and HuggingFace embeddings.  \n",
    "Ocasionally, HuggingFace sentence-transformers might not be available. We implement therefore a mechanism to work with local stored sentence transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.3.1)\n",
      "Collecting pip\n",
      "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.3.1\n",
      "    Uninstalling pip-23.3.1:\n",
      "      Successfully uninstalled pip-23.3.1\n",
      "Successfully installed pip-25.1.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.10/dist-packages (1.7.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "_kg_hide-input": false,
    "id": "b3XVQZx7TloD"
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectordb = FAISS.from_texts(\n",
    "    texts=chunks,\n",
    "    embedding=embeddings,\n",
    "    metadatas=metadatas\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbGY1WAjTloD"
   },
   "source": [
    "## Initialize chain   \n",
    "\n",
    "We are using `RetrievalQA` task chain utility from Langchain.  \n",
    "This will first query the vector database (using similarity search) with the prompt we are using.   \n",
    "Then, the query and the context retrieved (the documents that match with the query) are used to compose a prompt that instructs the LLM to answer to the query (**Generation**) using the information from the context retrieved (**Retrieval**). Therefore the name of the system, `Retrieval Augmented Generation`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "_kg_hide-input": false,
    "id": "sOpJgZ4pTloD"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "retriever = vectordb.as_retriever()\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NasBRq5CTloD"
   },
   "source": [
    "## Test the Retrieval-Augmented Generation\n",
    "\n",
    "\n",
    "We define a test function, that will run the query and time it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "_kg_hide-input": false,
    "id": "w_4BeHuhTloD"
   },
   "outputs": [],
   "source": [
    "def test_rag(qa, query):\n",
    "    \"\"\"\n",
    "    Test the Retrieval Augmented Generation (RAG) system.\n",
    "\n",
    "    Args:\n",
    "        qa (RetrievalQA.from_chain_type): Langchain function to perform RAG\n",
    "        query (str): query for the RAG system\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    time_start = time()\n",
    "    response = qa.run(query)\n",
    "    time_end = time()\n",
    "    total_time = f\"{round(time_end-time_start, 3)} sec.\"\n",
    "\n",
    "    full_response =  f\"Question: {query}\\nAnswer: {response}\\nTotal time: {total_time}\"\n",
    "    display(Markdown(colorize_text(full_response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rvJEA0BTloE"
   },
   "source": [
    "Let's check few queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "id": "GFtq_BMpTloJ",
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Проблема такая. Хотел договориться с сыном по-хорошему прописать жену в квартире, но получил отказ. Хотя сын сам не живет со мной уже почти 10 лет. Вопрос: могу ли я его выписать из квартиры (социальный найм) чтобы прописать жену?\n",
       "\n",
       "\n",
       "**<font color='green'>Answer:</font>** Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
       "\n",
       "Статья 153. Обязанность по внесению платы за жилое помещение и коммунальные услуги\n",
       "См. Энциклопедии, позиции высших судов и другие комментарии к статье 153 ЖК РФ\n",
       "См. схему \"Плата за жилое помещение и коммунальные услуги\"\n",
       "\n",
       "1. Граждане и организации обязаны своевременно и полностью вносить плату за жилое помещение и коммунальные услуги.\n",
       "\n",
       "2. Обязанность по внесению платы за жилое помещение и коммунальные услуги возникает у:\n",
       "\n",
       "1) нанимателя жилого помещения по договору социального найма с момента заключения такого договора;\n",
       "\n",
       "Федеральным законом от 21 июля 2014 г. N 217-ФЗ часть 2 статьи 153 настоящего Кодекса дополнена пунктом 1.1\n",
       "1.1) нанимателя жилого помещения по договору найма жилого помещения жилищного фонда социального использования с момента заключения данного договора;\n",
       "\n",
       "2) арендатора жилого помещения государственного или муниципального жилищного фонда с момента заключения соответствующего договора аренды;\n",
       "\n",
       "3) нанимателя жилого помещения по договору найма жилого помещения государственного или муниципального жилищного фонда с момента заключения такого договора;\n",
       "\n",
       "4) члена жилищного кооператива с момента предоставления жилого помещения жилищным кооперативом;\n",
       "\n",
       "4. В случае смерти члена жилищного кооператива его наследники имеют право на вступление в члены данного жилищного кооператива по решению общего собрания членов жилищного кооператива (конференции).\n",
       " 4. В случае смерти члена жилищного кооператива его наследники имеют право на вступление в члены данного жилищного кооператива по решению общего собрания членов жилищного кооператива (конференции). \n",
       "Статья 131. Преимущественное право вступления в члены жилищного кооператива в случае наследования пая\n",
       "См. Энциклопедии и другие комментарии к статье 131 ЖК РФ\n",
       "\n",
       "1. Наниматель жилого помещения по договору социального найма имеет право в установленном порядке:\n",
       "\n",
       "1) вселять в занимаемое жилое помещение иных лиц;\n",
       "\n",
       "2) сдавать жилое помещение в поднаем;\n",
       "\n",
       "3) разрешать проживание в жилом помещении временных жильцов;\n",
       "\n",
       "4) осуществлять обмен или замену занимаемого жилого помещения;\n",
       "\n",
       "5) требовать от наймодателя своевременного проведения капитального ремонта жилого помещения, надлежащего участия в содержании общего имущества в многоквартирном доме, а также предоставления коммунальных услуг.\n",
       "\n",
       "2. Наниматель жилого помещения по договору социального найма помимо указанных в части 1 настоящей статьи прав может иметь иные права, предусмотренные настоящим Кодексом, другими федеральными законами и договором социального найма.\n",
       "\n",
       "3. Наниматель жилого помещения по договору социального найма обязан:\n",
       "\n",
       "1) использовать жилое помещение по назначению и в пределах, которые установлены настоящим Кодексом;\n",
       "\n",
       "2) обеспечивать сохранность жилого помещения;\n",
       "\n",
       "3) поддерживать надлежащее состояние жилого помещения;\n",
       "\n",
       "4) проводить текущий ремонт жилого помещения;\n",
       "См. Методическое пособие по содержанию и ремонту жилищного фонда МДК 2-04.2004, утвержденное Госстроем РФ\n",
       "\n",
       "5) своевременно вносить плату за жилое помещение и коммунальные услуги;\n",
       "\n",
       "6) информировать наймодателя в установленные договором сроки об изменении оснований и условий, дающих право пользования жилым помещением по договору социального найма.\n",
       "\n",
       "3) плату за коммунальные услуги.\n",
       " 1. Плата за жилое помещение и коммунальные услуги для нанимателя жилого помещения, занимаемого по договору социального найма или договору найма жилого помещения государственного или муниципального жилищного фонда, включает в себя: \n",
       "1) плату за пользование жилым помещением (плата за наем);\n",
       " 1) плату за пользование жилым помещением (плата за наем); \n",
       "Пункт 2 изменен с 10 августа 2017 г. - Федеральный закон от 29 июля 2017 г. N 258-ФЗ\n",
       "См. предыдущую редакцию\n",
       "2) плату за содержание жилого помещения, включающую в себя плату за услуги, работы по управлению многоквартирным домом, за содержание и текущий ремонт общего имущества в многоквартирном доме, а также за холодную воду, горячую воду, электрическую энергию, потребляемые при использовании и содержании общего имущества в многоквартирном доме, за отведение сточных вод в целях содержания общего имущества в многоквартирном доме (далее также - коммунальные ресурсы, потребляемые при использовании и содержании общего имущества в многоквартирном доме). Капитальный ремонт общего имущества в многоквартирном доме проводится за счет собственника жилищного фонда;\n",
       " Пункт 2 изменен с 10 августа 2017 г. - Федеральный закон от 29 июля 2017 г. N 258-ФЗ\n",
       "См. предыдущую редакцию\n",
       "\n",
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Проблема такая. Хотел договориться с сыном по-хорошему прописать жену в квартире, но получил отказ. Хотя сын сам не живет со мной уже почти 10 лет. Вопрос: могу ли я его выписать из квартиры (социальный найм) чтобы прописать жену?\n",
       "Helpful \n",
       "\n",
       "**<font color='green'>Answer:</font>** No, не можем. Если сын уже не живет в квартире и не платит за нее, то не может быть с собойowner, и не может быть выписан из нее. Чтобы выписать человека из квартиры, он должен быть занимательем, т. е. он должен платить за проживание в квартире. Если он уже не платит, то не может быть занимательем. Если вы хотите, чтобы ваша жена прописалась в квартире, вы должны с сыном договориться по-хорошему, и выписать его из квартиры, а затем подать заявление о прописании вашей жены в квартире. Однако это может быть сложным и_time consuming процесс, и может потребовать разрешения суда. В любом случае, лучше всего с согласия сына и без судебных разбирательств решить эту проблему. \n",
       "\n",
       "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
       "\n",
       "Статья 153. Обязанность по внесению платы за жилое помещение и коммунальные услуги\n",
       "См. Энциклопедии, позиции высших судов и другие комментарии к статье 153 ЖК РФ\n",
       "См. схему \"Плата за жилое помещение и коммунальные услуги\"\n",
       "\n",
       "1. Граждане и организации обязаны своевременно и полностью вносить плату за жилое помещение и коммунальные услуги.\n",
       "\n",
       "2. Обязанность по внесению платы за жилое помещение и коммунальные услуги возникает у:\n",
       "\n",
       "1) нанимателя жилого помещения по договору социального найма с момента заключения такого договора;\n",
       "\n",
       "Федеральным законом от 21 июля 2014 г. Н 217-ФЗ часть 2 статьи 153 настоящего Кодекса дополнена пунктом 1.1\n",
       "1.1) нанимателя жилого помещения по договору найма жилого помещения жилищного фонда социального использования с момента заключения данного договора;\n",
       "\n",
       "2) арендатора жилого помещения государственного или муниципального жилищного фонда с момента заключения соответствующего договора аренды;\n",
       "\n",
       "3) нанимателя жилого помещения по договору найма жилого помещения государственного или муниципального жилищного фонда с момента заключения такого договора;\n",
       "\n",
       "4) члена жилищного кооператива с момента предоставления жилого помещения жилищным кооперативом;\n",
       "\n",
       "4. В случае смерти члена жилищного коопер\n",
       "\n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 21.573 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"Проблема такая. Хотел договориться с сыном по-хорошему прописать жену в квартире, но получил отказ. Хотя сын сам не живет со мной уже почти 10 лет. Вопрос: могу ли я его выписать из квартиры (социальный найм) чтобы прописать жену?\"\n",
    "test_rag(qa, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "U4KtrfhXTloJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Подскажите, пожалуйста. Мы с мужем в разводе, наш 7 летний ребенок прописан в квартире мужа, где собственником является его мать. Имею ли я право проживать вместе с ребенком в этой квартире. Спасибо!\n",
       "\n",
       "\n",
       "**<font color='green'>Answer:</font>** Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
       "\n",
       "1) государственная, муниципальная поддержка за счет средств бюджетов бюджетной системы Российской Федерации либо путем предоставления находящегося в государственной или муниципальной собственности имущества;\n",
       "\n",
       "См. Энциклопедии и другие комментарии к статье 84 ЖК РФ\n",
       "Выселение граждан из жилых помещений, предоставленных по договорам социального найма, производится в судебном порядке:\n",
       "\n",
       "1. Гражданин или юридическое лицо, желающие стать членом жилищного кооператива, подают в правление жилищного кооператива заявление о приеме в члены жилищного кооператива.\n",
       "\n",
       "Глава 16. Формирование фонда капитального ремонта на специальном счете\n",
       "\n",
       "\n",
       "\n",
       "**<font color='red'>Question:</font>** Подскажите, пожалуйста. Мы с мужем в разводе, наш 7 летний ребенок прописан в квартире мужа, где собственником является его мать. Имею ли я право проживать вместе с ребенком в этой квартире. Спасибо!\n",
       "Helpful \n",
       "\n",
       "**<font color='green'>Answer:</font>** You have the right to live with your child in the apartment, but it is not clear what the law says about this situation. In Russia, the law requires that a person who wants to live in a property owned by the state or a municipality must receive permission from the government or municipality. However, this law does not apply to the situation where a person lives with their child in an apartment owned by the mother of the child.\n",
       "\n",
       "It is likely that the law requires that the mother of the child, who is the owner of the apartment, allow the child to live with the mother and the child's father in the apartment. This is because the law in Russia requires that a person who lives in a property owned by the state or a municipality must receive permission from the government or municipality.\n",
       "\n",
       "However, the law does not provide clear guidance on this situation. In general, the law requires that a person who wants to live in a property owned by the mother of the child must receive permission from the mother. But since the child is a minor, the mother may be required to allow the child to live with the child's father.\n",
       "\n",
       "In any case, it is recommended that you consult with a lawyer who is familiar with the laws of Russia to get a more accurate answer to your question. The lawyer can provide you with guidance on the specific laws and regulations that apply to your situation. \n",
       "\n",
       "I don't know the answer to this question, I don't know. \n",
       "\n",
       "Please note that this answer is not a substitute for legal advice. If you have any legal issues, please consult a qualified lawyer. \n",
       "\n",
       "2) Обеспечивает обеспечение потребностей, потребности и благополучия граждан в области здравоохранения, образования, социальной защиты, физической культуры и спорта, культурного наследия и благотворительности.\n",
       "\n",
       "См. Энциклопедии и другие комментарии к статье 86 ЖК РФ\n",
       "\n",
       "3) Обеспечивает обеспечение потребностей, потребностей и благополучия граждан в области экономики, социальной защиты, физической культуры и спорта, культурного наследия и благотворительности.\n",
       "\n",
       "См. Энциклопедии и другие комментарии к статье 87 ЖК РФ\n",
       "\n",
       "4) Обеспечивает обеспечение потребностей, потребностей и благополучия граждан в области экономики, социальной защиты, физической культуры и спорта, культурного наследия и благотворительности.\n",
       "\n",
       "См. Энциклопедии и другие комментарии к статье 88 ЖК РФ\n",
       "\n",
       "5) Обеспечивает обеспечение потребностей, потребностей и благополучия граждан в области экономики, социальной защиты, физической культуры и спорта, культурного наследия и благотворительности.\n",
       "\n",
       "См. Энциклопедии и другие комментарии к статье 89 ЖК РФ\n",
       "\n",
       "6) Обеспечивает обеспечение потребностей, потребностей и благополучия граждан в области экономики, социальной защиты, физической культуры и спорта, культурного наследия и благотворительности.\n",
       "\n",
       "См. Энциклопедии и другие комментарии к статье 90 ЖК РФ\n",
       "\n",
       "7) Обеспечивает обеспечение потребностей, потребностей и благополучия граждан в области экономики, социальной защиты, физической культуры и спорта, культурного наследия и благотворительности.\n",
       "\n",
       "См. Энциклопедии и другие комментарии к статье 91 ЖК РФ\n",
       "\n",
       "8) Обеспечивает обеспечение потребностей, потребностей и благополучия граждан в области экономики, социальной защиты, физической культуры и спорта, культурного наследия и благотворительности.\n",
       "\n",
       "См. Энциклопедии и другие комментарии к статье 92 ЖК РФ\n",
       "\n",
       "9) Обеспечивает обеспечение потребностей, потребностей и благополучия граждан в области экономики, социальной защиты, физической культуры и спорта, культурного наследия и благотворительности.\n",
       "\n",
       "См. Энциклопедии и другие комментарии к статье 93 ЖК РФ\n",
       "\n",
       "10) Обеспечивает обеспечение потребностей, потребностей и благополучия граждан в области экономики, социальной защиты, физической культуры и спорта, культурного наследия и благотворительности.\n",
       "\n",
       "См. Энциклопедии и другие комментарии к статье 94 ЖК РФ\n",
       "\n",
       "11) Обеспечивает обеспечение потребностей, потребностей и благополучия граждан в области экономики, социальной защиты, физической культуры и спорта, культурного наследия и благотворительности.\n",
       "\n",
       "См. Энциклопедии и другие комментарии к статье 95 ЖК РФ\n",
       "\n",
       "12) Обеспечивает обеспечение потребностей, потребностей и благополучия граждан в области экономики, социальной защиты, физической культуры и спорта, культурного наследия и благотворительности.\n",
       "\n",
       "См. Энциклопедии и другие комментарии к статье 96 ЖК РФ\n",
       "\n",
       "13) Обеспечивает обеспечение потребностей, потребностей и благополучия граждан в области экономики, социальной защиты, физической культуры и спорта, культурного наследия и благотворительности.\n",
       "\n",
       "См. Энциклопедии и другие комментарии к статье 97 ЖК РФ\n",
       "\n",
       "14) Обеспечивает обеспечение потребностей, потребностей и благополучия граждан в области экономики, социальной защиты, физической культуры и спорта, культурного наследия и благотворительности.\n",
       "\n",
       "См. Энциклопедии и другие комментарии к статье 98 ЖК РФ\n",
       "\n",
       "15) Обеспечивает обеспечение потребностей, потребностей и благополучия граждан в области экономики, социальной защиты, физической культуры и спорта, культурного наследия и благотворительности.\n",
       "\n",
       "См. Энциклопедии и другие комментарии к статье 99 ЖК РФ\n",
       "\n",
       "16) Обеспечивает обеспечение потребностей, потребностей и благополучия граждан в области экономики, социальной защиты, физической культуры и спорта, культурного наследия и благотворительности.\n",
       "\n",
       "См. Энциклопедии и другие комментарии к статье 100 ЖК РФ\n",
       "\n",
       "17) Обеспечивает обеспечение потребностей, потребностей и благополучия граждан в области экономики, социальной защиты, физической культуры и спорта, культурного наследия и благотворительности.\n",
       "\n",
       "См. Энциклопедии и другие комментарии к статье 101 ЖК РФ\n",
       "\n",
       "18) Обеспечивает обеспечение потребностей, потребностей и благополучия граждан в области экономики, социальной защиты, физической культуры и спорта, культурного наследия и благотворительности.\n",
       "\n",
       "См. Энциклопедии и другие комментарии к статье 102 ЖК РФ\n",
       "\n",
       "19) Обеспечивает обеспечение потребностей, потребностей и благополучия граждан в области экономики, социальной защиты, физической культуры и спорта, культурного наследия и благотворительности.\n",
       "\n",
       "См. Энциклопедии и другие комментарии к статье 103 ЖК РФ\n",
       "\n",
       "20) Обеспечивает обеспечение потребностей, потребностей и благополучия граждан в области экономики, социальной защиты, физической культуры и спорта, культурного наследия и благотворительности.\n",
       "\n",
       "См. Энциклопедии и другие комментарии к статье 104 ЖК РФ\n",
       "\n",
       "21) Обеспечивает обеспечение потребностей, потребностей и благополучия граждан в области экономики, социальной защиты, физической культуры и спорта, культурного наследия и благотворительности.\n",
       "\n",
       "См. Энциклопедии и другие комментарии к статье 105 ЖК РФ\n",
       "\n",
       "22) Обеспечивает обеспечение потребностей, потребностей и благополучия граждан в области экономики, социальной защиты, физической культуры и спорта, культурного наследия и благотворительности.\n",
       "\n",
       "См. Энциклопедии и другие комментарии к статье\n",
       "\n",
       "\n",
       "**<font color='magenta'>Total time:</font>** 59.876 sec."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"Подскажите, пожалуйста. Мы с мужем в разводе, наш 7 летний ребенок прописан в квартире мужа, где собственником является его мать. Имею ли я право проживать вместе с ребенком в этой квартире. Спасибо!\"\n",
    "test_rag(qa, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9OqniYrTloJ"
   },
   "source": [
    "## Document sources\n",
    "\n",
    "Let's check the documents sources, for the last query run.  \n",
    "\n",
    "In order to do this, we will perform the following steps:\n",
    "* We run a similarity search in the vector database;\n",
    "* We loop through the documents returned;\n",
    "* Print, for each document, the documents source, from the metadata, and the page content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "collapsed": true,
    "id": "YoW4wdcfTloK",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Подскажите, пожалуйста. Мы с мужем в разводе, наш 7 летний ребенок прописан в квартире мужа, где собственником является его мать. Имею ли я право проживать вместе с ребенком в этой квартире. Спасибо!\n",
      "Retrieved documents: 4\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'source'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs:\n\u001b[1;32m      5\u001b[0m     doc_details \u001b[38;5;241m=\u001b[39m doc\u001b[38;5;241m.\u001b[39mto_json()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkwargs\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSource: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mdoc_details\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msource\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText: \u001b[39m\u001b[38;5;124m\"\u001b[39m, doc_details[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpage_content\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'source'"
     ]
    }
   ],
   "source": [
    "docs = vectordb.similarity_search(query)\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Retrieved documents: {len(docs)}\")\n",
    "for doc in docs:\n",
    "    doc_details = doc.to_json()['kwargs']\n",
    "    print(\"Source: \", doc_details['metadata']['source'])\n",
    "    print(\"Text: \", doc_details['page_content'], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bhon6N1FTloK"
   },
   "source": [
    "# Conclusions\n",
    "\n",
    "\n",
    "We used Langchain, ChromaDB and Llama3 as a LLM to build a Retrieval Augmented Generation solution. For testing, we were using the EU AI Act from 2023.  \n",
    "The answers to questions from EU AI Act are correct, when using a RAG model.  \n",
    "\n",
    "To improve the solution, we will have to refine the RAG implementation, first by optimizing the embeddings, then by using more complex RAG schemes.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2740486,
     "sourceId": 4737381,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4617783,
     "sourceId": 7870110,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 39106,
     "modelInstanceId": 28083,
     "sourceId": 33551,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30559,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
